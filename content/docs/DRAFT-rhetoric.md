"This is a decent video about some of what I was talking about earlier, it gets
into how think tanks have worked historically and how ""the marketplace of
ideas"" is now actually a very real marketplace with lots of ? thrown around
with high impact on public opinion and political policy, but it is not
incentivized based on truth/rigor: https://youtu.be/UsPvDYO19ys"

"Intellectual grifters are most successful when their audience is uneducated
and/or bad at critically examining ideas/logic/evidence. Better education,
training people to be better at examining what they hear critically/skeptically
helps a lot but it doesn't change the way the system is structured/incentivized
poorly. And the systemic stuff is the part that's also gotten much worse
recently with the internet and the way information spreads

"

The systemic part of the issue is also the part that no one has any good
solution for yet (afaik)

"Thanks for sharing!  Yeah that makes a lot of sense.  One book I read recently
argues that decision makers in our big society don't have much 'skin in the
game', which makes it easier to make less rigorous decisions that end up having
big impact"

Also democratic decisions where no one person has ultimate responsibility also
probly help worsen the issue you pose too

"Yeah and there's a lot more $ and fame to be made in peddling ideology
(whether subtlely or not), which is part of what that video talks about"

It would be cool if there was a better way to push direct feedback/consequences
for decisions to the deciders

That I think would inspire more rigor

Deciders + idea spreaders

"I think in politics a lot of the deciders are supposed to represent the people
and be beholden to them. So if the people value rigor/facts/expertise than that
controlling power comes from our democracy, from the people. But you need a
strong democracy and education for that to work"

Feedback also depends on the people giving feedback being educated/informed and
not having a strong collective bias

"I think the ""idea spreaders"" are really hard to control, but maybe there
could be more regulation on how that kind of thing is funded or something. Idk"

"Yes.  I think an important piece to also consider tho is where the burden of
effort lies, because rigor takes effort.  Individual voters generally
don't/can't put in a lot of effort testing ideas.  Policy makers imo will put
in the minimum effort required for each individual policy so that they can be
productive.  If there was someone more directly responsible for outcomes, that
person would be directly incentivizes to put in the effort I think"

"Idea spreaders right now are DEFINITELY not incentivizes to put in the effort,
as you imply"

Lol inventivized

Incentivized

"Imo loosely regulated idea spreading is fine, as long as the people deciding
what ideas are implemented actually test the stuff they implement and have
responsibility for it going right"

Of course if we can't get the decision point right then we should probably
regulate the idea spreading

Just joining a work mtg fyi

"I think the highest burden of rigor is only meant to be placed on experts
researching some specific field, and there is a softer burden of critical
thinking that should be placed on leaders. In a culture that values education,
it would also be something valued/recognized a little more by everyone. The
larger problem with leaders isn't really effort imo, it's integrity. Plenty of
leaders are working very hard and putting in plenty of effort, just not towards
the people's interests, because there is some other incentive they care more
about (?/influence/fame/power, idea spreaders want to get paid or be famous,
politicians need favor with the right groups to be successful, etc.). On the
systemic side, our systems need to incentivize integrity, because they don't
currently. On the people side, our culture could recognize and incentivize
integrity more if the people recognize and value it more

"

"Many idea spreaders put in loads of effort, they are incredibly hard workers.
But they're not working to inform, they're grifters"

And it doesn't matter how rigorous our experts are if culturally we don't trust
them and are more trusting of the grifters (and the grifted). Or if our leaders
actively undermine them.

"Yes true.  I was assuming policy makers are not putting enough effort behind
the task of rigorously deciding what ""experts"" have rigorous evidence for
their ideas, and that is why idea spreaders can work their ideas into
implementation.  Like you're saying, policy makers also have their own biases
that further disrupt their ability to pick the right idea.  My thought is that
if we can make it very clear/consequential when a wrong idea is implemented,
maybe we can incentivize the selection of better ideas."

"I agree that scientists/experts should be held to high standards of rigor, but
policy makers should be able to do the job of reviewing scientific work and
ensuring that is in fact well done before running with it"

Or they could just trust it if there is a very clear widespread consensus among
the scientists who actually know how to review that work

"I think getting people to listen to the experts at all comes first. And doing
something about corrupt actors and grifters. That problem is much more
insidious than an ordinary bias or issue of rigor, it comes down to
honesty/integrity"

"Yeah +1 to getting people to listen to experts comes first.  My proposed
mechanism for how to do that in this conversation is to give decision makers
more ownership/accountability/responsibility  over their decisions, so that
there are actual repercussions to not listening to experts.  I'm hoping that if
we can tie trusting grifters to clear failure we can help fix this problem."

"For example, setting some kind of goal or metric for healthcare costs (Andrew
yang proposed doing this kind of thing in his platform) , then setting a target
gives a clear pass/fail signal.  Then politicians would propose plans that they
think will pass.  Then they try them and the failures are rigorously
scrutinized and punished with e.g. no reelection"

Doing this kind of thing on small scales first would minimize risk

Co2 concentration in atmosphere is another good metric

Or something more real that co2 impacts

I also agree that a more informed/critical thinking populace is very important

"I worry it's not enough tho, or maybe not tangible enough?"

"Even informed ppl can be fooled, especially if they spend less time critically
examining ideas than those people who carefully crafted the ideas"

"Yeah I agree, I definitely think where we can we should quantify things and
look for feedback where we can (definitely a mathy approach with the great
intention of trying to be objective) but I also think that can be really tricky
with a lot if things, especially if we try to attribute blame/credit to
specific people/decisions. If we set up the metrics poorly and put too much
trust in them we run the risk of creating new gameable systems for people to
exploit. Decisions may also be good for the long term but have short term
costs, and decisions can have far-reaching effects which impact the
metrics/data of future decisions and leaders. This is the kind of approach most
corporations try to take and a common issue is that it becomes too focused on
the short term, potentially at the expense of the long term. Whatever metrics
we use should be chosen carefully, and the metrics will likely need to be
changed/improved over time. And there are lots of things that will still need
to be examined qualitatively, without a clear metric

"

Yeah this stuff is messy : /

"I think some of the biggest things that need changing are in infrastructure.
There aren't a lot of good direct metrics for that, it's the kind of thing
that's really important to almost every area but in intangible/indirect ways.
Still, there are clear problems with clear solutions there, a lot kf which
relate to teasing out these bad incentives I've talked about and improving the
strength and health of our democracy and checks and balances. Imo that is some
of the most critical stuff that needs fixing, and it's in the way of fixing so
many other more direct/tangible things"

Yep.  One thing I hope for in the future is that more people will be able to
spend their time doing this stuff as our economy gets better at satisfying our
basic needs.

"I also agree that a more informed public has intangible impact and isn't
enough, but I think it's another feature of the health/stability of our
country. If we fixed all of our systems and made them much better but the
public was still very uninformed, things could still devolve over time. I think
structures (systems and policies) and culture (people, public opinion, values,
opinions, education) are linked and it can be either a vicious spiral or a
virtuous one"

It takes a lot of effort to find and champion the issues you're talking about

Yep

"I'm glad we have this is text, maybe I'll try to summarize this weekend and
post as an essay/blog post"

At least for my own future reference

"And the culture ones not tangible, it isn't really even an issue we can fight
for, it's the rippling effect of all of our interactions and experiences"

If that's ok with you

Yeah that lack of direct actionability bothers me : /

Yeah go for it

"The thing you said about time is part of the argument tor things like UBI. The
thing is, no matter how efficient our economy gets at producing, that doesn't
necessarily give the people time if there is artificial scarcity. As in, there
is enough food/housing/whatever to go around but people don't have access to it
unless they work ridiculous hours (and maybe not even then). This is a really
large topic, but it's part of why people like to hate on capitalism recently.
There are a lot of ways artificial scarcity is created for the sake of
greed/profit, and if ? is what you care about, creating/maintaining artificial
scarcity is actually what people with a lot of ? are incentivized to do in the
current system"

👍

"If things ""trickled down"", all the efficiency would benefit the people, but
there is nothing in the system to make that so. It might sometimes in certain
ways or might not. At the end of the day, the people with the money have the
power for it to trickle or not and the system doesn't make them"

Yeah we live in a very wierd society in that way.  I guess at least it allows
for interesting people like elon musk to exist

"I'm getting really tired of powerful people being so ""interesting"" haha"

"Hey are you/Hari busy tomorrow?  I was thinking it might be fun to come hang
out at your place during the day, if nothing else just for a change of scenery
: )"

I'm free/down :)

"Ok, I'll try to find a break in the rain around midday if that's cool"

Hari says he's busy at 7

Ok np

But he's free the rest of the day

👍

On way

👍

Btw we birding up now

"Another point about socialism: whenever a well-regarded historical figure
supports socialism or other ""radical"" ideas (not actually radical but things
we tend to strawman as radical), we tend to filter that out whenever we
teach/celebrate that person's achievements. E.g. MLK was a democratic
socialist, so was bertrand russell. But also apparently there's more
technicalities to the definitions of different kinds of socialism which I don't
totally understand, like social democrat and democratic socialist are 2
different kinds of socialism that are both not the scary communism kind. There
might be other kinds that have been tried before, idk"

That historical whitewashing doesn't just apply to people but also historical
examples of successful democratic socialist governments

"I'm reading the last book MLK wrote and it's amazing so far. He touches on
some of what we talked about wrt anger and emotion. He points out that rage can
replace reason if we let it but also says people need to rise up with
indignation to demand necessary reforms be instituted. So blind reasonless rage
is bad, but properly directed, rational moral indignation is good. Not just
good but necessary for the right change to occur. Sending snaps of the actual
quotes"

"""rocklike intransigence"" (people become entrenched and won't change their
minds) and ""sophisticated manipulation"" (e.g. propaganda and maliciously
strategic actions like voter suppression, gerrymandering, undermining or
circumventing democracy) captures the major ways progress is difficult even
when you have a good solution which could fix or vastly improve a problem if
implemented. Maintaining a large complex system that works for the people is
already difficult work (like it is in software engineering) but these other
forces add a whole new level of difficulty, which comes from antagonistic
humans abusing their power and platforms. That part of the struggle is not a
systems design problem, it is more like a battle. These bad actors (think of
them as black hat hackers) are very driven, and it will take a lot of
collective drive from the public to get change through despite their efforts
(preferably more from reasonable indignation than reasonless rage. But the less
productive rage will always be there unless the problem improves)

"

"There is a pattern throughout history where if a tension like this exists and
worsens over time, the anger and frustration becomes more intense and
widespread until it leads to revolution (a violent and chaotic one if rage wins
out)"

"You can break down the ""sophisticated manipulation"" by manipulation of
people and culture (propaganda) or systemic manipulation (the other
""maliciously strategic"" stuff I mentioned). A lot of propaganda serves to
diffuse reasonable/justified indignation so change is less likely to occur
(downplay the severity or validity of the problem), or redirect it to something
else (twisting things away from the source of the problem to the wrong cause,
or even another completely fake issue). But if problems persist, some kind of
rage always remains, however it is processed/directed"

"Problems in infrastructure are more abstract and less clearly/directly tied to
the problems people get emotional about. I think it's because of that lack of
emotional drive that it's especially hard to get changes through in those
areas. This is also part of why I think the perspective of math is important,
not just because it allows us to see things in a clear and objective way (as
clear/objective as humanly possible), but it also gets us thinking about
abstract ideas and structure. Better math education means the public is more
comfortable doing that"

"Ok I'm done spamming you with walls of text for now, sorry"

It's interesting!  And yeah I think rage/passion is necessary sometimes to keep
people behind a cause.  Im maybe in denial about it's usefulness

"More generally, imo the harm of emotion comes down to ""reacting before
thinking/reasoning"". But reacting AFTER thinking things through (and also
being open to the idea that you might be wrong and being willing to rethink) is
perfectly rational. Furthermore, sometimes strong emotions indicate a person is
MORE aware of reality, not the other way around. If you notice your house is on
fire and your emotional state is exactly the same as if it wasn't on fire, I
wouldn't say that makes you ""rational"", it's more likely you haven't yet come
to terms with the fact that your house is on fire."

"Yeah I agree.  I will say that from a completely naive observers perspective,
the fact that someone is strongly emotional is not necessarily correlated to
their viewpoint being accurate.  And since emotions often demand strong
reaction (e.g. support), a completely naive observer may be savvy to avoid the
situation to avoid backing the wrong perspective (e.g. propaganda).  Of course,
this only applied for naive observers who haven't seen all perspectives and
don't have enough info."

"In any discussion, ideas exist separately from people and can be examined on
their own merit, regardless of the perceived emotional state of the person
presenting them or any other details not relevant to what is/isn't true or
valid. What this comes down to is rhetoric vs epistemology, ""winning the
debate"" vs getting at the truth/validity of the ideas themselves. The former
isn't rational, it's just what's effective. The latter is how we can actually
try to be rational, and we can try to take that approach as much as possible in
a ""best effort"" way to learn as much as possible from any discussion,
isolating/evaluating all points made by all sides independently."

"Rhetoric is still an important tool, and it can be used virtuously or
viciously. Virtuous rhetoric might simplify things or illustrate things in
imperfect ways but minimize the gap between that and reality (and often uses
careful wording to draw attention to the oversimplification or caveats of a
point), vicious rhetoric maximizes the gap ruthlessly to win the debate at all
costs, only simulating virtuosity where necessary as a further rhetorical
strategy"

"Really, savvy observers know the difference between rhetoric and valid
logic/methodology and can see through vicious rhetoric. Education makes vicious
rhetoric less effective and virtuous rhetoric more effective"

"Not just education, but also emotional intelligence and wisdom, to know your
own biases and common poor shortcuts, and learn how to change or correct for
them. Or even just knowing when they're there in a big way, and having a
healthy dose of doubt/skepticism as a result"

"If your level of certainty is much higher than your level of
knowledge/understanding of a particular area, it's a sure sign of some bad
shortcuts. It could be a wrong belief that's held onto strongly and forced into
any lens we look through, it could be we think of certain ideas as completely
interchangeable when they're not (but may still be related in a weaker way), it
could be a type of confident and charismatic speaking really appeals to us,
speech that is unemotional in tone, etc."

"For me this is one of the most productive aspects of thinking about these
things - you learn a lot about yourself and other people along the way, in ways
that can't be planned or forseen. If you decide to take some kind of action,
you'll do so in a less half-baked way. And even if you don't do anything with a
direct outsized impact, this process of honest examination, careful thought and
introspection can have rippling positive effects on the world and yourself"

"I was talking with Claire some more about this and it's becoming more clear to
me (partially based on her observations of me) that I am currently
uncomfortable with ethos and pathos based arguments because I see them as
shortcuts to an end goal that can hide problems.  This feeling has persisted
strongly in me probably because I haven't faced challenges where those
shortcuts are necessary to succeed.  You are right that real rhetoric is
necessary to accomplish societal goals; I think I personally just haven't faced
many/any of them so I don't see it's true value.  As you can already maybe see
from our conversations, I (currently) take a more passive approach to these
issues in an attempt to understand them deeply (mistrusting shortcuts), maybe
idealistically thinking that I even can do that.  I don't think this would win
me much success in changing hearts/minds or even doing anything at all besides
avoiding or running from the problem."

"I agree that virtuous rhetoric is very useful, and distrusting ALL rhetoric
makes learning anything really hard.  I think some people selectively take the
""reject all rhetoric"" stance to avoid inconvenient truths"

"(but they have to believe some rhetoric, like I do)"

"I deeply distrust rhetoric and shortcuts and I think it's healthy. I am not
advocating for taking more shortcuts internally, but rather for awareness of
the shortcuts that exist and a ""best effort"" to prune/refine them and not put
certainty in them or hold onto them so tightly. This is why I also prefer
cooperative discussion to competitive debate. In the former, rhetoric is not
necessarily needed (or if it is needed it's not relied on as heavily) and both
parties benefit from understanding each other fully without appeals or
posturing, and it can also be a more honest/open conversation, without fear of
showing something which could be perceived as weakness (expressing emotion,
admitting to not knowing certain things, admitting to mistakes in thinking,
being wrong, etc.). Openness requires that all parties in the discussion can
see past the rhetorical shortcuts and are invested in understanding the best
version of what each person has to say (steel-manning), while allowing
cooperative corrections/refinement of the ideas for everyone's benefit."

"I'm also advocating for understanding rhetoric, how it fools other people and
how we fool ourselves. We are not logical emotionless robots no matter how hard
we try to be, and trying to view ourselves in that way tends to decrease our
self awareness, hurting our ability to see our biases/shortcuts clearly. The
shortcuts/biases are still there but we lose our greatest tool for finding them
and push them further out of our conscious thoughts, making them more likely to
deepen than to diminish. If we do this emotional suppression and also convince
ourselves we're being rational, we run the risk of becoming overly certain and
confident in ourselves while being less aware of the weakness of our own
thinking."

"Rhetoric becomes important when speaking to people who we aren't sure we can
have that kind of nice, healthy discussion I described with or when we speak
with any kind of platform. I think the distrust of emotional people thing you
were describing IS a rhetorical shortcut based on ethos. Full logos would take
what is said and consider it for its own merit, based on logic and whatever
other evidence/methodology is being used, treating things like emotional tone
as just noise, not relevant to the ideas (this is how an emotionless robot
would interpret what is said)."

"If you were to eliminate all shortcuts and maintain perfect awareness of your
assumptions, you'd be doing math (or what math aspires to be, there's no
guarantee mathematicians don't also make mistakes, but at least everything
stated so clearly and unambiguously that the mistakes are not so hidden).
Everything past that is progressively less solid and more uncertain, which is
fine as long as you have some awareness and flexibility.

"

"And yeah, people move the goalposts all the time for how rigorous/logical
arguments need to be to be convincing and hold inconsistent standards for
evaluating truth (as high as possible for opponents and as low as possible for
themselves). People are suddenly very skeptical and great at finding flaws when
looking at something they don't want to believe."

Sorry for writing another essay :p

"It's great, I'M sorry I haven't been responding as elequently : P.  Good point
about the emotional -> less trust bridge being ethos based.  That's a good
perspective; and it makes it easier for me to see that my correlation there is
not necessarily ""reasonable"""








Issues with Reasoning

To improve our condition in the world, one of the best tools we humans have is
"distributed reasoning".  I'll define this as the ability of people to build
useful models of the world in their heads based on models of the world
communicated to them by other people.  Through this process, new people, or
people new to an area of knowledge can shortcut the learning process, enabling
novel stuff to happen.

Here I'll assume that the majority of communication that enabled distributed
reasoning is [rhetorical](https://en.wikipedia.org/wiki/Rhetoric) in nature;
that is, it involves an asymmetric exchange between a teacher trying to
persuade a student of something.  I use the word "persuade" because it captures
the changing of mind that is required when learning something new - or
unlearning something.

Because our minds have limited memory, attention span, and processing power,
teachers must provide incomplete arguments in their lessons.  It is impossible
in most cases to provide an airtight explanation for why what the teacher is
saying is right.  To keep arguments persuasive, teachers often fall back on
assumptions, appeals to authority (e.g. "what this expert says is the gold
truth"), appeals to common sense (e.g. "this is obvious"), or appeals to
emotion (e.g. statistics presented in a scary way).

Although this may seem problematic, it's actually necessary to employ these
techniques because, practically, people need to learn and have limited
resources with which to do so.  An alternative, pure
[epistemology](https://en.wikipedia.org/wiki/Epistemology) is usually too slow
in most contexts.  For those who need to make real decisions now, going down
epistemologic rabbit holes is a good recipe for failure.  

In most cases, this system works extremely well.  People learn skills quickly
with it and, if the teacher's lesson was misleading, they get fast feedback
when what they are trying to do fails.  This is very clear in trade-like
contexts, like programming or building stuff.  Hard science education also uses
this system well.  Most models of the world taught to students in science
classes have serious problems with them, but are still useful stepping stones
on the path to either further understanding or useful application.

A bit of a breakdown occurs when the decisions people make based on rhetorical
arguments have unclear or delayed consequences.  Here is where being more
epistemological becomes very useful.  However, it's sometimes even unclear when
decisions even have unclear results!  For example, a clear cause-effect
relationship with a subtle, hard-to-notice additional effect.  These
relationships are everywhere in complex systems like human societies.

Over history our ability to execute rhetorical communication has only
improved due to the written word and other media.  In the last generation the
ability of any person to participate both as a teacher and a student has been
scaled up to a global level.

This intensification of our ability to distributed-ly reason, coupled with the
unclear cause-effect relationships found in the complex systems we are
reasoning about leads us to some unpleasant problems.  Chief among these is the
rampant application of very focused rhetorical arguments to societal problems.
Anyone can throw down an argument with holes or that doesn't consider the full
picture and gain a following, since people are historically very used to
absorbing such arguments.  Since societal problems are so complex, thinking
epistemological-ly more often than not leads to dead ends or unless findings,
which further discourages eager activists from taking that route.

So, as a result, we find ourselves in a sticky situation.  The complexity of
our world has become daunting, but the average quality of our solutions to its
problems are low.  Therefore, the effort required to dig through and find a
good solution is increasing.  

Unfortunately, the personal incentives/consequences for doing/not doing this
work don't always seem to be aligned with its importance.  One great example is
economic policy - punishment for failures is pretty low[^1].  It is too easy
for thought leaders to recommend arguments for implementation without
consequences when those arguments lead to problems.  This is especially
problematic when those thought leaders have incentives other than those of the
people they are serving.

[^1]: See writings of Nicholas Taleb
